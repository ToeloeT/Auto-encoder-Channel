{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "num_GPU = 1\n",
    "mem_growth = True\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.get_logger().setLevel('INFO')\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "\n",
    "tf.config.experimental.set_visible_devices(gpus[num_GPU], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[num_GPU], mem_growth)\n",
    "print('Used GPU: {}. Memory growth: {}'.format(num_GPU, mem_growth))\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# from settings import SETTINGS\n",
    "from AWGN_settings_1TxU import SETTINGS\n",
    "from libphy.coding.Parity_Bit import Parity_Bit\n",
    "from libphy.rg.Interleaver import Interleaver\n",
    "from libphy.modulation.GS import GS\n",
    "from libphy.modulation.QAM import QAM\n",
    "from libphy.rxnn.RXNN import RXNN\n",
    "from libphy.coding.BP_Decoder_SumProd import BP_Decoder\n",
    "from libch.channel.channel_preproc import ChannelPreProcess\n",
    "from libch.channel.dataset_gen_parser import DatasetGenerator\n",
    "from libch.channel.multipath_channel import MultiPathChannel\n",
    "from libphy.waveform.OFDM import OFDM\n",
    "\n",
    "# tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libphy.modulation.GS import GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "libphy.modulation.GS.GS"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_user = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SysGS(Model):\n",
    "        \n",
    "    # velocity in m/s\n",
    "    def __init__(self, training, fine_tuning = False, **kwargs):\n",
    "        super(SysGS, self).__init__(**kwargs)\n",
    "        \n",
    "        # Training/Evaluating\n",
    "        self.training = tf.constant(training, tf.bool)\n",
    "        # Fine tuning or not. At fine tuning GS nontrainable; otherwise, trainable\n",
    "        self.fine_tuning = tf.constant(fine_tuning, tf.bool)\n",
    "\n",
    "        H = SETTINGS['PCM'][SETTINGS['code_rate']]\n",
    "        self.bit_info_per_codeword = H.shape[1] - H.shape[0]\n",
    "        self.bit_par_per_codeword = H.shape[0]\n",
    "        self.codeword_length = H.shape[1]\n",
    "        \n",
    "        assert self.codeword_length % SETTINGS['bit_per_cu'] == 0\n",
    "        self.sym_per_codeword = self.codeword_length // SETTINGS['bit_per_cu']\n",
    "        \n",
    "        if training:\n",
    "            self.optimizer = tf.optimizers.Adam(SETTINGS['learning_rate'])\n",
    "                \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        # Trainable modulation\n",
    "        self.gs = GS(SETTINGS['bit_per_cu'])\n",
    "        \n",
    "         # At fine tuning phase, set to non-trainable\n",
    "        if self.fine_tuning:\n",
    "            self.gs.trainable = False\n",
    "            print('GS nontrainable')\n",
    "\n",
    "        # Non-trainable modulation\n",
    "        self.qam = QAM(SETTINGS['bit_per_cu'])\n",
    "                        \n",
    "        #  Channel encoder and decoder\n",
    "        self.encoder = Parity_Bit(SETTINGS['PCM'][SETTINGS['code_rate']], SETTINGS['PCM_STD'][SETTINGS['code_rate']])\n",
    "        self.decoder = BP_Decoder(SETTINGS['PCM'][SETTINGS['code_rate']], SETTINGS['BP_iter'])\n",
    "        \n",
    "        # Interleaver\n",
    "        self.interleaver = Interleaver()\n",
    "        \n",
    "        # NN receivers #\n",
    "        self.rx={}\n",
    "        for uu in range(SETTINGS['total_user_']):\n",
    "            self.rx[uu] = RXNN(SETTINGS['bit_per_cu'])\n",
    "            self.rx[uu]._name = 'rx_'+str(uu)\n",
    "        # self.rx = RXNN(SETTINGS['bit_per_cu'])\n",
    "\n",
    "        # OFDM modulation (no CP) and channel\n",
    "        self.ofdm = OFDM(SETTINGS['num_subc'], SETTINGS['CP_duration'], False)\n",
    "        \n",
    "    #@tf.function ####\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        snr_db, alpha, theta = inputs\n",
    "        \n",
    "        self.summary()\n",
    "        \n",
    "        # Noise parameters\n",
    "        noise_power_db = -snr_db\n",
    "        noise_std = tf.sqrt(0.5*(tf.pow(10.0, noise_power_db/10.0)))\n",
    "        noise_std = tf.expand_dims(noise_std, axis=1)\n",
    "        \n",
    "        if self.training:\n",
    "            num_frames = SETTINGS['train_batch_size']\n",
    "        else:\n",
    "            num_frames = SETTINGS['eval_batch_size']\n",
    "        data_symb_per_frames = SETTINGS['num_subc']*SETTINGS['block_length']\n",
    "        bit_per_frames = data_symb_per_frames*SETTINGS['bit_per_cu']\n",
    "        codewords_per_frame = tf.math.floordiv(bit_per_frames, self.codeword_length)\n",
    "        number_padding_bits = bit_per_frames - codewords_per_frame*self.codeword_length\n",
    "        \n",
    "        # Genarating codewords\n",
    "        bit_info = tf.random.uniform(shape=[num_frames*codewords_per_frame, self.bit_info_per_codeword], minval=0, maxval=2, dtype=tf.int32)\n",
    "        if self.training:\n",
    "            bit_parity = tf.random.uniform(shape=[num_frames*codewords_per_frame, self.bit_par_per_codeword], minval=0, maxval=2, dtype=tf.int32)\n",
    "        else:\n",
    "            bit_parity = self.encoder(bit_info)\n",
    "        codewords = tf.concat([bit_info, bit_parity], axis=1)\n",
    "        \n",
    "        # Padding\n",
    "        codewords = tf.reshape(codewords, [num_frames, codewords_per_frame, self.codeword_length])\n",
    "        codewords = tf.reshape(codewords, [num_frames, codewords_per_frame*self.codeword_length])\n",
    "        if tf.greater(number_padding_bits, 0):\n",
    "            pad = tf.random.uniform([num_frames, number_padding_bits], minval=0, maxval=2, dtype=tf.int32)\n",
    "            codewords = tf.concat([codewords, pad], axis=1)\n",
    "        \n",
    "        # Interleaving\n",
    "        codewords = self.interleaver.interleave(codewords)\n",
    "        \n",
    "        # Mapping and modulation\n",
    "        bit_labels = tf.reshape(codewords, [num_frames, data_symb_per_frames, SETTINGS['bit_per_cu']])\n",
    "        A = tf.constant(np.flip([[[2**i for i in range(SETTINGS['bit_per_cu'].numpy())]]]), dtype=tf.int32)\n",
    "        s = tf.reduce_sum(bit_labels*A, axis=2)\n",
    "        \n",
    "        # Modulation\n",
    "        if SETTINGS['shaping_style'] == 1:\n",
    "            x = self.gs(s)\n",
    "        else:\n",
    "            x = self.qam(s)        \n",
    "        \n",
    "        # to subframe\n",
    "        x = tf.reshape(x, [num_frames, SETTINGS['num_subc'], SETTINGS['block_length']])\n",
    "        \n",
    "        # OFDM modulation\n",
    "        x = self.ofdm.modulate(x)\n",
    "        \n",
    "        # Nonlinear PA processing\n",
    "        PA_Nonlinear = SETTINGS['PA_Nonlinear']\n",
    "        if PA_Nonlinear == 1:\n",
    "            alpha_A = SETTINGS['alpha_A']\n",
    "            beta_A = SETTINGS['beta_A']\n",
    "            alpha_p = SETTINGS['alpha_p']\n",
    "            beta_p = SETTINGS['beta_p']\n",
    "            x_norm = SETTINGS['x_norm']\n",
    "            # Normalized gain\n",
    "            normal_factor = alpha_A/(1+beta_A)\n",
    "            # Magnititudes\n",
    "            a_t = tf.math.abs(x)/x_norm\n",
    "            # print(tf.shape(x))\n",
    "            C_a_t = alpha_A/(1+beta_A*tf.math.square(a_t))/normal_factor\n",
    "            phi_a_t = alpha_p*tf.math.square(a_t)/(1+beta_p*tf.math.square(a_t))\n",
    "            C_a_t = tf.complex(tf.math.cos(phi_a_t)*C_a_t, tf.math.sin(phi_a_t)*C_a_t)\n",
    "            # print(tf.shape(C_a_t))\n",
    "            x = C_a_t*x\n",
    "\n",
    "        # Initial ber/rate\n",
    "#         ber = tf.zeros(shape=(SETTINGS['total_user']), dtype=tf.float32)\n",
    "#         rate = tf.zeros(shape=(SETTINGS['total_user']), dtype=tf.float32)\n",
    "\n",
    "            ###############\n",
    "            # Channel #x\n",
    "            ###############\n",
    "\n",
    "        # AWGN Channel\n",
    "        noise = (tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std), tf.random.normal(tf.shape(x), mean=0.0, stddev=noise_std))\n",
    "        noise = tf.complex(noise[0], noise[1])\n",
    "\n",
    "        y = x + noise\n",
    "\n",
    "        # IQ Imbalance Setting\n",
    "#             alpha_x = alpha[:,uu]\n",
    "#         alpha_x = alpha[:,now_user]\n",
    "        alpha_x = alpha\n",
    "            # print(alpha_x.shape)\n",
    "            # print('alpha_x', alpha_x.numpy())\n",
    "        alpha_x = tf.expand_dims(alpha_x, axis=1)\n",
    "        alpha_x = tf.tile(alpha_x, [1, SETTINGS['num_subc']*SETTINGS['block_length']])\n",
    "#         theta_x = theta[:,now_user]\n",
    "        theta_x = theta\n",
    "        theta_x = tf.expand_dims(theta_x, axis=1)\n",
    "        theta_x = tf.tile(theta_x, [1, SETTINGS['num_subc']*SETTINGS['block_length']])\n",
    "        mu = tf.complex((1.0 + alpha_x*tf.math.cos(theta_x))/2.0, (alpha_x*tf.math.sin(theta_x))/2.0)\n",
    "        nu = tf.complex((1.0 - alpha_x*tf.math.cos(theta_x))/2.0, (alpha_x*tf.math.sin(theta_x))/2.0)\n",
    "        y = mu * y + nu * tf.math.conj(y)\n",
    "\n",
    "        # OFDM demodulation #x\n",
    "        y = self.ofdm.demodulate(y)\n",
    "\n",
    "        # Receivers #x\n",
    "        snr_db_ext = tf.tile(tf.expand_dims(tf.expand_dims(snr_db, axis=1), axis=2), [1, SETTINGS['num_subc'], SETTINGS['block_length']])\n",
    "        # NN receiver #x\n",
    "        rx_u = self.rx[now_user]\n",
    "        # print('rx_u[]', rx_u)\n",
    "        llr = rx_u(y, snr_db_ext, self.training)\n",
    "        # Extracting data symbols\n",
    "        llr = tf.reshape(llr, [num_frames, data_symb_per_frames, SETTINGS['bit_per_cu']])\n",
    "        llr_ = llr # To comute the BCE\n",
    "        llr = tf.reshape(llr, [num_frames, data_symb_per_frames*SETTINGS['bit_per_cu']])\n",
    "\n",
    "        # Deinterleaving\n",
    "        llr = self.interleaver.de_interleave(llr)\n",
    "\n",
    "        # Remove padding\n",
    "        if tf.greater(number_padding_bits, 0):\n",
    "            llr = llr[:,:-number_padding_bits]\n",
    "\n",
    "        # Decoding #x\n",
    "        if not self.training:\n",
    "                llr = tf.reshape(llr, [num_frames, codewords_per_frame, self.codeword_length])\n",
    "                llr = tf.reshape(llr, [num_frames*codewords_per_frame, self.codeword_length])\n",
    "                llr_dec = self.decoder(llr)\n",
    "\n",
    "                # Compute BER per frame\n",
    "                llr_dec = tf.reshape(llr_dec, [num_frames, codewords_per_frame, self.codeword_length])\n",
    "                bit_info_hat = llr_dec[:,:,:self.bit_info_per_codeword]\n",
    "                bit_info_hat = tf.reshape(bit_info_hat, [num_frames, codewords_per_frame*self.bit_info_per_codeword])\n",
    "                bit_info_hat = (tf.sign(bit_info_hat) + 1) / 2\n",
    "                bit_info_hat = tf.cast(bit_info_hat, tf.int32)\n",
    "                bit_info = tf.reshape(bit_info, [num_frames, codewords_per_frame, self.bit_info_per_codeword])\n",
    "                bit_info = tf.reshape(bit_info, [num_frames, codewords_per_frame*self.bit_info_per_codeword])\n",
    "                bit_nerr = tf.cast(tf.equal(bit_info, bit_info_hat), tf.float32)\n",
    "                ber_ = 1. - tf.reduce_mean(bit_nerr)\n",
    "        else:\n",
    "                ber_ = tf.constant(-1., tf.float32)\n",
    "\n",
    "#         ber_list = tf.unstack(ber)\n",
    "#         ber_list[uu] = ber_\n",
    "            # print('ber_', ber_.numpy())\n",
    "#         ber = tf.stack(ber_list)\n",
    "        ber = ber_\n",
    "            # print('ber', ber.numpy())\n",
    "\n",
    "            # Compute rate (BMI)\n",
    "        bit_labels = tf.cast(bit_labels, tf.float32)\n",
    "        bit_labels = tf.stop_gradient(bit_labels)\n",
    "        hs = tf.cast(SETTINGS['bit_per_cu'], tf.float32)\n",
    "        bce = tf.nn.sigmoid_cross_entropy_with_logits(labels=bit_labels, logits=llr_)\n",
    "        rate_ = bce/np.log(2.)\n",
    "        rate_ = tf.reduce_mean(hs - tf.reduce_sum(rate_, axis=2))\n",
    "\n",
    "#         rate_list = tf.unstack(rate)\n",
    "#         rate_list[uu] = rate_\n",
    "#             # print('rate_', rate_.numpy())\n",
    "#         rate = tf.stack(rate_list)\n",
    "        rate = rate_\n",
    "            # print('rate',rate.numpy())\n",
    "            \n",
    "        return ber, rate\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        W = self.get_weights()\n",
    "        with open(fn, 'wb') as f:\n",
    "            pickle.dump(W, f)\n",
    "\n",
    "    def load_model(self, fn):\n",
    "        with open(fn, 'rb') as f:\n",
    "            W = pickle.load(f)\n",
    "        self.set_weights(W)\n",
    "            \n",
    "    def train(self):\n",
    "        \n",
    "        #@tf.function ####\n",
    "        def _train():\n",
    "\n",
    "            i = tf.constant(0, tf.int32)\n",
    "            # Initialize loss weightst\n",
    "            alf = tf.ones([SETTINGS['total_user']], tf.float32)/tf.cast(SETTINGS['total_user'], tf.float32)\n",
    "            # Initialize IQ imbalance parameter sets\n",
    "            alpha_x = np.zeros([SETTINGS['train_batch_size'], SETTINGS['total_user']])\n",
    "            theta_x = np.zeros([SETTINGS['train_batch_size'], SETTINGS['total_user']])\n",
    "            while tf.less(i, SETTINGS['train_iterations']):\n",
    "                for uu in range(SETTINGS['total_user_']):\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        global now_user\n",
    "                        now_user = uu\n",
    "                    # Generating random SNRs\n",
    "                        snr_db = tf.random.uniform([SETTINGS['train_batch_size']], minval=SETTINGS['train_SNR_range'][0], maxval=SETTINGS['train_SNR_range'][1], dtype=tf.float32)\n",
    "\n",
    "                        # Set IQ imbalance parameters\n",
    "                        IQ_Imbalance = SETTINGS['IQ_Imbalance']\n",
    "                        if IQ_Imbalance == 2:  # Random\n",
    "                            # Uniform distributed\n",
    "\n",
    "    #                             alpha_x[:,uu] = np.random.uniform(SETTINGS['alpha'][uu]-SETTINGS['alpha_d'][uu], SETTINGS['alpha'][uu]+SETTINGS['alpha_d'][uu], \n",
    "    #                                                               (SETTINGS['train_batch_size'],) )\n",
    "    #                             theta_x[:,uu] = np.random.uniform(SETTINGS['theta'][uu]-SETTINGS['theta_d'][uu], SETTINGS['theta'][uu]+SETTINGS['theta_d'][uu], \n",
    "    #                                                               (SETTINGS['train_batch_size'],) )*np.pi\n",
    "                                alpha_x = np.random.uniform(SETTINGS['alpha'][uu]-SETTINGS['alpha_d'][uu], SETTINGS['alpha'][uu]+SETTINGS['alpha_d'][uu], \n",
    "                                                                  (SETTINGS['train_batch_size'],) )\n",
    "                                theta_x = np.random.uniform(SETTINGS['theta'][uu]-SETTINGS['theta_d'][uu], SETTINGS['theta'][uu]+SETTINGS['theta_d'][uu], \n",
    "                                                                  (SETTINGS['train_batch_size'],) )*np.pi\n",
    "    #                     print(alpha_xt.shape)\n",
    "                            # print('tr alpha_x', alpha_x)\n",
    "                                alpha = tf.convert_to_tensor(alpha_x)\n",
    "                                theta = tf.convert_to_tensor(theta_x)\n",
    "    #                             # Running the system\n",
    "                                _, rate = self((snr_db, alpha, theta))\n",
    "                                loss_x = -rate\n",
    "\n",
    "                                # print('tr loss_x', loss_x.numpy())\n",
    "                                # print('tr alf', alf.numpy())\n",
    "\n",
    "                                loss = alf*loss_x\n",
    "                                # print('tr wt loss', loss)\n",
    "                                loss = tf.reduce_sum(loss)\n",
    "                                # print('tr loss after sum', loss.numpy())\n",
    "                                alf = loss_x/tf.reduce_sum(loss_x)\n",
    "                                # print('tr alf update', alf.numpy())\n",
    "                    gradients = tape.gradient(loss, self.trainable_weights)\n",
    "                    self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "                print(\"Epoch [Epoch: %3d/%3d]\" %(i+1,SETTINGS['train_iterations']))\n",
    "#                 if tf.equal(tf.math.floormod(i, 100), 0):\n",
    "#                     tf.summary.scalar('loss', loss, step=tf.cast(i, tf.int64))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "        _train()\n",
    "        global now_user\n",
    "        now_user = 0\n",
    "        \n",
    "    def ft_train(self): # For fine-tuning training after AE training\n",
    "        \n",
    "        #@tf.function ####\n",
    "        def _ft_train():\n",
    "            i = tf.constant(0, tf.int32)\n",
    "            \n",
    "            while tf.less(i, SETTINGS['ft_train_iterations']):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    # Generating random SNRs\n",
    "                    snr_db = tf.random.uniform([SETTINGS['train_batch_size']], minval=SETTINGS['train_SNR_range'][0], maxval=SETTINGS['train_SNR_range'][1], dtype=tf.float32)\n",
    "                    # Set IQ imbalance parameters\n",
    "                    alpha = tf.cast(tf.fill([SETTINGS['train_batch_size'], SETTINGS['total_user']], SETTINGS['ft_alpha']), tf.float32)\n",
    "                    theta = tf.cast(tf.fill([SETTINGS['train_batch_size'], SETTINGS['total_user']], SETTINGS['ft_theta']), tf.float32)*np.pi\n",
    "\n",
    "                    # Running the system\n",
    "                    _, rate = self((snr_db, alpha, theta))\n",
    "                    # print('ft tr rate', rate.numpy())\n",
    "                    loss = -rate[0]\n",
    "                    # print('ft tr loss', loss.numpy())\n",
    "                    \n",
    "                gradients = tape.gradient(loss, self.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "                if tf.equal(tf.math.floormod(i, 100), 0):\n",
    "                    tf.summary.scalar('loss', loss, step=tf.cast(i, tf.int64))\n",
    "\n",
    "                i = i + 1\n",
    "            \n",
    "        _ft_train()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sys, snr_db, alpha, theta):    \n",
    "        \n",
    "    #@tf.function  ####\n",
    "    def _evaluate():\n",
    "        # can add in config\n",
    "        ber = tf.zeros(shape=(), dtype=tf.float32)\n",
    "        rate = tf.zeros(shape=(), dtype=tf.float32)\n",
    "        for i in tf.range(SETTINGS['eval_iter']):\n",
    "            # Running the system\n",
    "            ber_temp = []\n",
    "            rate_temp = []\n",
    "            for uu in range(SETTINGS['total_user_']):\n",
    "                global now_user\n",
    "                now_user = uu\n",
    "                ber_, rate_ = sys((snr_db, alpha[:,uu], theta[:,uu]))\n",
    "                # print('ev ber_', ber_.numpy())\n",
    "                # Cumulating\n",
    "                ber_temp.append(ber_)\n",
    "                rate_temp.append(ber_)\n",
    "#                 ber = ber + ber_\n",
    "                # print('ev ber', ber.numpy())\n",
    "#                 rate = rate + rate_\n",
    "        # print('ev before total ber', ber.numpy())\n",
    "            ber = ber + tf.convert_to_tensor(np.array(ber_temp))\n",
    "            rate = rate + tf.convert_to_tensor(np.array(rate_temp))\n",
    "        ber = ber / tf.cast(SETTINGS['eval_iter'], tf.float32)\n",
    "        rate = rate / tf.cast(SETTINGS['eval_iter'], tf.float32)\n",
    "        \n",
    "        # print('ev after total ber', ber.numpy())\n",
    "        \n",
    "        return ber, rate\n",
    "        \n",
    "    ber, rate = _evaluate()\n",
    "    global now_user\n",
    "    now_user = 0\n",
    "    return ber.numpy(), rate.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from datetime import datetime\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    today = str(datetime.now())[:10].replace('-','_')\n",
    "    print(today)\n",
    "    answear = []\n",
    "    # Create the folder where to store the model files\n",
    "    mod_dir = 'models/GS_OFDM_AWGN_O2M_{0}_{1}'.format(SETTINGS['IQ_Imbalance'], today)\n",
    "    if not os.path.exists(mod_dir):\n",
    "        os.mkdir(mod_dir)\n",
    "\n",
    "    # Create the folder where to store the results files\n",
    "    results_dir = 'results/GS_OFDM_AWGN_O2M_{0}_{1}'.format(SETTINGS['IQ_Imbalance'], today)\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.mkdir(results_dir)\n",
    "\n",
    "    # Save settings\n",
    "    setting_file = 'AWGN_settings_1TxU.py'\n",
    "    shutil.copy2(setting_file, '{0}/{1}'.format(results_dir,setting_file))        \n",
    "        \n",
    "    for seed in SETTINGS['seed']:\n",
    "    \n",
    "        ##############################################\n",
    "        # Training\n",
    "        ##############################################\n",
    "\n",
    "        # GS system\n",
    "        sys = SysGS(True, False)\n",
    "\n",
    "        # Training and saving model\n",
    "        tf.random.set_seed(seed)\n",
    "        log_writer = tf.summary.create_file_writer('logs/GS_OFDM_AWGN_O2M-{1}/Sd{0}'.format(seed, SETTINGS['IQ_Imbalance']))\n",
    "        with log_writer.as_default():\n",
    "            sys.train()\n",
    "\n",
    "        sys.save_model('{1}/Sd{0}.mod'.format(seed, mod_dir))\n",
    "        \n",
    "        ##############################################\n",
    "        # Evaluation\n",
    "        ##############################################\n",
    "\n",
    "        # GS system\n",
    "        sys = SysGS(False, False)\n",
    "\n",
    "        # Loading trained model. We need to do a 'foo' iteration first to construct the system\n",
    "        snr_db = tf.cast(tf.fill([SETTINGS['eval_batch_size']], SETTINGS['eval_SNR_range'][0]), tf.float32)\n",
    "        alpha = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['eval_alphas'][0]), tf.float32)\n",
    "        theta = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['eval_thetas'][0]), tf.float32)*np.pi\n",
    "        for uu in range(SETTINGS['total_user_']):\n",
    "            global now_user\n",
    "            now_user = uu\n",
    "            sys((snr_db, alpha[:,uu], theta[:,uu]))\n",
    "        sys.load_model('{1}/Sd{0}.mod'.format(seed, mod_dir))\n",
    "        \n",
    "        # To get constellation\n",
    "        if SETTINGS['shaping_style'] == 1:\n",
    "            Get_Const = sys.gs.get_const()\n",
    "            Constellation = Get_Const.numpy()\n",
    "            print(Constellation)\n",
    "            # Save results\n",
    "            result_loc = '{1}/Constellation_Sd{0}.mat'.format(seed, results_dir)\n",
    "            mdic = {\"Constellation\": Constellation}\n",
    "            sio.savemat(result_loc, mdic)\n",
    "        alpha_list = []\n",
    "        theta_list = []\n",
    "        # Running simulations\n",
    "        SNRs = np.linspace(SETTINGS['eval_SNR_range'][0], SETTINGS['eval_SNR_range'][1], SETTINGS['eval_SNR_range'][2])\n",
    "        IQ_Imbalance = SETTINGS['IQ_Imbalance']\n",
    "        if IQ_Imbalance == 1:  # No IQ imbalance\n",
    "            alpha_ = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], 1.0), tf.float32)\n",
    "            theta_ = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], 0.0), tf.float32)\n",
    "        else:  # Fixed/Random\n",
    "            # Initialize IQ imbalance parameter sets\n",
    "            alpha_x = np.zeros([SETTINGS['eval_batch_size'], SETTINGS['total_user']])\n",
    "            theta_x = np.zeros([SETTINGS['eval_batch_size'], SETTINGS['total_user']])\n",
    "            for uu in range(SETTINGS['total_user_']): \n",
    "                alpha_x[:,uu] = tf.cast(tf.fill([SETTINGS['eval_batch_size']], SETTINGS['eval_alphas'][uu]), tf.float32)\n",
    "                theta_x[:,uu] = tf.cast(tf.fill([SETTINGS['eval_batch_size']], SETTINGS['eval_thetas'][uu]), tf.float32)*np.pi\n",
    "            # print('ev alpha_x', alpha_x)\n",
    "            alpha_ = tf.convert_to_tensor(alpha_x)\n",
    "            theta_ = tf.convert_to_tensor(theta_x)\n",
    "        \n",
    "        # print(alpha_.shape)\n",
    "        # print(theta_.shape)\n",
    "        RESULTS = {}\n",
    "        BERs = []\n",
    "        RATEs = []\n",
    "        for snr in tqdm(SNRs):\n",
    "            snr_ = tf.cast(tf.fill([SETTINGS['eval_batch_size']], snr), tf.float32)\n",
    "            ber, rate = evaluate(sys, snr_, alpha_, theta_)\n",
    "            BERs.append(ber)\n",
    "            RATEs.append(rate)\n",
    "        RESULTS = (SNRs, BERs, RATEs)\n",
    "        answear.append([SNRs, BERs, RATEs])\n",
    "        # Saving results\n",
    "        with open('{1}/Sd{0}.res'.format(seed, results_dir), 'wb') as f:\n",
    "            pickle.dump(RESULTS, f)\n",
    "\n",
    "        # Check if fine tuning phase is required\n",
    "        if SETTINGS['finetuning'] == 1 and SETTINGS['IQ_Imbalance'] == 2:\n",
    "            \n",
    "            ##############################################\n",
    "            # Fine tuning phase Training (Supervised learning)\n",
    "            ##############################################\n",
    "            # GS system\n",
    "            ft_sys = SysGS(True, True)\n",
    "\n",
    "            # Loading AE trained model. We need to do a 'foo' iteration first to construct the system\n",
    "            snr_db = tf.cast(tf.fill([SETTINGS['eval_batch_size']], SETTINGS['eval_SNR_range'][0]), tf.float32)\n",
    "            alpha = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_alpha']), tf.float32)\n",
    "            theta = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_theta']), tf.float32)*np.pi\n",
    "            ft_sys((snr_db, alpha, theta))\n",
    "            ft_sys.load_model('{1}/Sd{0}.mod'.format(seed, mod_dir))\n",
    "\n",
    "            tf.random.set_seed(seed)\n",
    "            log_writer = tf.summary.create_file_writer('logs/GS_OFDM_AWGN_O2M-{1}/Sd{0}'.format(seed, SETTINGS['IQ_Imbalance']))\n",
    "            with log_writer.as_default():\n",
    "                ft_sys.ft_train()\n",
    "\n",
    "            # Save FT trained model\n",
    "            ft_sys.save_model('{1}/FT-Sd{0}.mod'.format(seed, mod_dir))\n",
    "\n",
    "            ##############################################\n",
    "            # Fine tuning phase Evaluation\n",
    "            ##############################################\n",
    "\n",
    "            # GS system\n",
    "            ft_sys = SysGS(False, True)\n",
    "            \n",
    "            # Loading trained model. We need to do a 'foo' iteration first to construct the system\n",
    "            snr_db = tf.cast(tf.fill([SETTINGS['eval_batch_size']], SETTINGS['eval_SNR_range'][0]), tf.float32)\n",
    "            alpha = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_alpha']), tf.float32)\n",
    "            theta = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_theta']), tf.float32)*np.pi\n",
    "            ft_sys((snr_db, alpha, theta))\n",
    "            ft_sys.load_model('{1}/FT-Sd{0}.mod'.format(seed, mod_dir))\n",
    "\n",
    "            # Running simulations\n",
    "            SNRs = np.linspace(SETTINGS['eval_SNR_range'][0], SETTINGS['eval_SNR_range'][1], SETTINGS['eval_SNR_range'][2])\n",
    "            alpha_ = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_alpha']), tf.float32)\n",
    "            theta_ = tf.cast(tf.fill([SETTINGS['eval_batch_size'], SETTINGS['total_user']], SETTINGS['ft_theta']), tf.float32)*np.pi\n",
    "            RESULTS = {}\n",
    "            BERs = []\n",
    "            RATEs = []\n",
    "            for snr in tqdm(SNRs):\n",
    "                snr_ = tf.cast(tf.fill([SETTINGS['eval_batch_size']], snr), tf.float32)\n",
    "                ber, rate = evaluate(ft_sys, snr_, alpha_, theta_)\n",
    "                BERs.append(ber)\n",
    "                RATEs.append(rate)\n",
    "            RESULTS = (SNRs, BERs, RATEs)\n",
    "\n",
    "            # Saving results\n",
    "            with open('{1}/FT-Sd{0}.res'.format(seed, results_dir), 'wb') as f:\n",
    "                pickle.dump(RESULTS, f)\n",
    "\n",
    "            # Save models\n",
    "            model_file = '{1}/FT-Sd{0}.mod'.format(seed, mod_dir)\n",
    "            target_model_file = '{1}/FT-Sd{0}.mod'.format(seed, results_dir)\n",
    "            shutil.copy2(model_file, target_model_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f948818e0b8>,\n",
       " <matplotlib.lines.Line2D at 0x7f948818e0f0>,\n",
       " <matplotlib.lines.Line2D at 0x7f948818e1d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f948818e278>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(answear[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
